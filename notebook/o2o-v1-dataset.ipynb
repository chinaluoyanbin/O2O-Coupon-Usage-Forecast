{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c95603c932daefc690377e27525dcee2d28777df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "%matplotlib inline\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger_output = logging.FileHandler('o2o-v1-dataset.log', mode='a')\n",
    "logger_output.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"[%(asctime)s]: %(message)s\")\n",
    "logger_output.setFormatter(formatter)\n",
    "logger.addHandler(logger_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "fe04bdfccbb63a9d5995d224b898734989fe9cb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiscount_rate(s):\n",
    "    if s == 'null':\n",
    "        return 1\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return 1 - float(temp[1]) / float(temp[0])\n",
    "    else:\n",
    "        return float(s)\n",
    "    \n",
    "    \n",
    "def getIsManjian(s):\n",
    "    if ':' in s:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def getDiscountMan(s):\n",
    "    if s == 'null':\n",
    "        return np.nan\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return float(temp[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def getDiscountJian(s):\n",
    "    if s == 'null':\n",
    "        return np.nan\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return float(temp[1])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def get_date_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]), int(s[0][4:6]), int(s[0][6:8])) - date(int(s[1][0:4]), int(s[1][4:6]), int(s[1][6:8]))).days\n",
    "\n",
    "\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if 'null' in s:\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]), int(s[0][4:6]), int(s[0][6:8])) - date(int(s[1][0:4]), int(s[1][4:6]), int(s[1][6:8]))).days <= 15:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_firstlastone(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  #those only receive once\n",
    "    \n",
    "\n",
    "def getO21(x, y):\n",
    "    y = y.split(':')\n",
    "    count = 0\n",
    "    for el in y:\n",
    "        if el >= x:\n",
    "            count += 1\n",
    "    return count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "364e92f239e54305fa338ea2498e3c447b5e7b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113640, 7) (1754884, 8) (11429826, 7)\n",
      "(137167, 8) (995240, 8) (5982320, 7)\n",
      "(258446, 8) (812779, 8) (6098712, 7)\n",
      "(113640, 7) (1036975, 8) (7431432, 7)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "off_test = pd.read_csv('../input/ccf_offline_stage1_test_revised.csv', keep_default_na=False)\n",
    "off_train = pd.read_csv('../input/ccf_offline_stage1_train.csv', keep_default_na=False)\n",
    "on_train = pd.read_csv('../input/ccf_online_stage1_train.csv', keep_default_na=False)\n",
    "\n",
    "off_test['discount_rate'] = off_test.Discount_rate.apply(getDiscount_rate)\n",
    "off_train['discount_rate'] = off_train.Discount_rate.apply(getDiscount_rate)\n",
    "\n",
    "print(off_test.shape, off_train.shape, on_train.shape)\n",
    "\n",
    "# 分割数据集\n",
    "# dateset3: 20160701~20160731 (113640), features3 from 20160315~20160630\n",
    "# dateset2: 20160515~20160615 (258446), features2 from 20160201~20160514  \n",
    "# dateset1: 20160414~20160514 (138303), features1 from 20160101~20160413\n",
    "# for dataset1\n",
    "start, end = '20160414', '20160514'\n",
    "dataset1 = off_train[(start <= off_train.Date_received) & (off_train.Date_received <= end)]\n",
    "# 提取label\n",
    "dataset1['label'] = dataset1.Date_received + ':' + dataset1.Date\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(columns=['Date'], inplace=True)\n",
    "start, end = '20160101', '20160413'\n",
    "off_feature1 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature1 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "# for dateset2\n",
    "start, end = '20160515', '20160615'\n",
    "dataset2 = off_train[(start <= off_train.Date_received) & (off_train.Date_received <= end)]\n",
    "# 提取label\n",
    "dataset2['label'] = dataset2.Date_received + ':' + dataset2.Date\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(columns=['Date'], inplace=True)\n",
    "start, end = '20160201', '20160514'\n",
    "off_feature2 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature2 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "# for dataset3\n",
    "dataset3 = off_test.copy()\n",
    "dataset3.Coupon_id = dataset3.Coupon_id.astype(str)\n",
    "dataset3.Date_received = dataset3.Date_received.astype(str)\n",
    "start, end = '20160315', '20160630'\n",
    "off_feature3 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature3 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "del off_test, off_train, on_train\n",
    "print(dataset1.shape, off_feature1.shape, on_feature1.shape)\n",
    "print(dataset2.shape, off_feature2.shape, on_feature2.shape)\n",
    "print(dataset3.shape, off_feature3.shape, on_feature3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cf9e5e1a9351446d7b4f2484b8cc0a2ad1d6caab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_offline_feature(dataset, feature):\n",
    "    \n",
    "    \"\"\"\n",
    "    3. 提取线下特征\n",
    "    \"\"\"\n",
    "\n",
    "    # weekday\n",
    "    dataset['weekday'] = dataset.Date_received.astype('str').apply(lambda x: date(int(x[0: 4]), int(x[4: 6]), int(x[6: 8])).weekday() + 1)\n",
    "    # is_weekend\n",
    "    dataset['is_weekend'] = dataset.weekday.apply(lambda x: 1 if x in (6, 7) else 0)\n",
    "    # day\n",
    "    dataset['day'] = dataset.Date_received.astype('str').apply(lambda x: int(x[6:8]))\n",
    "    \n",
    "    consume_use_coupon = feature[(feature.Coupon_id != 'null') & (feature.Date != 'null')]  #用户领取优惠券消费信息\n",
    "    consume_common = feature[(feature.Coupon_id == 'null') & (feature.Date != 'null')]  #用户普通消费信息\n",
    "    receive_coupon_not_consume = feature[(feature.Coupon_id != 'null') & (feature.Date == 'null')]  #用户领取优惠券但未使用信息\n",
    "    receive_coupon = feature[feature.Coupon_id != 'null']  #用户领取优惠券信息\n",
    "    consume = feature[feature.Date != 'null']  #用户消费信息\n",
    "    \n",
    "    # ===========================\n",
    "    # ====== user字段 ===========\n",
    "    # ===========================\n",
    "    user = feature[['User_id']]\n",
    "    user.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # 线下使用优惠券消费的次数\n",
    "    # u1\n",
    "    t = consume_use_coupon[['User_id']]\n",
    "    t['u1'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "    \n",
    "    # 领取优惠券的总次数\n",
    "    # u4\n",
    "    t = receive_coupon[['User_id']]\n",
    "    t['u4'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 优惠券核销率\n",
    "    # u5\n",
    "    user.u1.fillna(0, inplace=True)\n",
    "    user['u5'] = user.u1 / user.u4\n",
    "    \n",
    "    # 一共消费多少次\n",
    "    # u7\n",
    "    t = consume[['User_id']]\n",
    "    t['u7'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "    \n",
    "    # 领取优惠券到使用优惠券的最小间隔时间\n",
    "    # u28\n",
    "    t = consume_use_coupon[['User_id', 'Date_received', 'Date']]\n",
    "    t['date_date_received'] = t.Date + ':' + t.Date_received\n",
    "    t['u28'] = t.date_date_received.apply(get_date_gap)\n",
    "    t = t[['User_id', 'u28']].groupby('User_id').agg('min').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 领取优惠券到使用优惠券的最大间隔时间\n",
    "    # u29\n",
    "    t = consume_use_coupon[['User_id', 'Date_received', 'Date']]\n",
    "    t['date_date_received'] = t.Date + ':' + t.Date_received\n",
    "    t['u29'] = t.date_date_received.apply(get_date_gap)\n",
    "    t = t[['User_id', 'u29']].groupby('User_id').agg('max').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 领取优惠券到使用优惠券的平均间隔时间\n",
    "    # u40\n",
    "    t = consume_use_coupon[['User_id', 'Date_received', 'Date']]\n",
    "    t['date_date_received'] = t.Date + ':' + t.Date_received\n",
    "    t['u40'] = t.date_date_received.apply(get_date_gap)\n",
    "    t = t[['User_id', 'u40']].groupby('User_id').agg('mean').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户消费的不同商家数量\n",
    "    # u30\n",
    "    t = consume[['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='u30')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户优惠券消费的平均距离\n",
    "    # u31\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('mean').reset_index(name='u31')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户优惠券消费的最小距离\n",
    "    # u32\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('min').reset_index(name='u32')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户优惠券消费的最大距离\n",
    "    # u33\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('max').reset_index(name='u33')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "    \n",
    "    dataset = pd.merge(dataset, user, how='left', on='User_id')\n",
    "    del user\n",
    "    \n",
    "    # ==============================\n",
    "    # ====== merchant字段 ===========\n",
    "    # ==============================\n",
    "    merchant = feature[['Merchant_id']]\n",
    "    merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # 商家被消费次数\n",
    "    # m1\n",
    "    t = consume[['Merchant_id']]\n",
    "    t['m1'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被优惠券消费次数\n",
    "    # m2\n",
    "    t = consume_use_coupon[['Merchant_id']]\n",
    "    t['m2'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "    \n",
    "    # 商户优惠券被领取次数\n",
    "    # m4\n",
    "    t = receive_coupon[['Merchant_id']]\n",
    "    t['m4'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券被领取后的核销率\n",
    "    # m5 = m2 / m4\n",
    "    merchant.m2.fillna(0, inplace=True)\n",
    "    merchant['m5'] = merchant.m2 / merchant.m4\n",
    "    \n",
    "    # 商家被核销优惠券中的用户-商家平均距离\n",
    "    # m20\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('mean').reset_index(name='m20')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最小距离\n",
    "    # m21\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('min').reset_index(name='m21')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最大距离\n",
    "    # m22\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('max').reset_index(name='m22')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被优惠券消费次数占消费次数比重\n",
    "    # m23\n",
    "    merchant['m23'] = merchant.m2 / merchant.m1\n",
    "\n",
    "    # 商家被消费的不同的用户数量\n",
    "    # m24\n",
    "    t = consume[['Merchant_id', 'User_id']]\n",
    "    t = t.groupby('Merchant_id').User_id.agg('count').reset_index(name='m24')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "    \n",
    "    dataset = pd.merge(dataset, merchant, how='left', on='Merchant_id')\n",
    "    del merchant\n",
    "    \n",
    "    # ==============================\n",
    "    # ====== coupon字段 =============\n",
    "    # ==============================\n",
    "    # 是否满减\n",
    "    # c6\n",
    "    dataset['c6'] = dataset.Discount_rate.apply(getIsManjian)\n",
    "    \n",
    "    # 满减优惠券中的满\n",
    "    # c12\n",
    "    dataset['c12'] = dataset.Discount_rate.apply(getDiscountMan)\n",
    "\n",
    "    # 满减优惠券中的减\n",
    "    # c13\n",
    "    dataset['c13'] = dataset.Discount_rate.apply(getDiscountJian)\n",
    "    \n",
    "    # label窗里的coupon，在特征窗中被消费过的数目\n",
    "    # c14\n",
    "    t = consume_use_coupon[['Coupon_id']]\n",
    "    t['c14'] = 1\n",
    "    t = t.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Coupon_id')\n",
    "    \n",
    "    # label窗里的coupon，在特征窗中被领取过的数目\n",
    "    # c15\n",
    "    t = receive_coupon[['Coupon_id']]\n",
    "    t['c15'] = 1\n",
    "    t = t.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Coupon_id')\n",
    "    \n",
    "    # label窗里的coupon，在特征窗中的核销率\n",
    "    # c16\n",
    "    dataset.c14.fillna(0, inplace=True)\n",
    "    dataset['c16'] = dataset.c14 / dataset.c15\n",
    "    \n",
    "    # ========================================\n",
    "    # ====== user merchant 双字段 =============\n",
    "    # ========================================\n",
    "    user_merchant = feature[['User_id', 'Merchant_id']]\n",
    "    user_merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # 用户领取商家的优惠券次数\n",
    "    # um4\n",
    "    t = receive_coupon[['User_id', 'Merchant_id']]\n",
    "    t['um4'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "    \n",
    "    # 用户领取商家的优惠券后核销次数\n",
    "    # um6\n",
    "    t = consume_use_coupon[['User_id', 'Merchant_id']]\n",
    "    t['um6'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "    \n",
    "    # 用户领取商家的优惠券后核销率\n",
    "    # um7\n",
    "    user_merchant.um6.fillna(0, inplace=True)\n",
    "    user_merchant['um7'] = user_merchant.um6 / user_merchant.um4\n",
    "    \n",
    "    # 用户在商店总共消费过几次\n",
    "    # um9\n",
    "    t = consume[['User_id', 'Merchant_id']]\n",
    "    t['um9'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户在商店普通消费次数\n",
    "    # um10\n",
    "    t = consume_common[['User_id', 'Merchant_id']]\n",
    "    t['um10'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "    \n",
    "    # 用户商家数量统计\n",
    "    # um12\n",
    "    t = feature[['User_id', 'Merchant_id']]\n",
    "    t['um12'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "    \n",
    "    # 用户商家优惠券消费占总消费次数的比重\n",
    "    # um13\n",
    "    user_merchant['um13'] = user_merchant.um6 / user_merchant.um9\n",
    "    \n",
    "    # 用户商家普通消费占总消费次数比重\n",
    "    # um14\n",
    "    user_merchant.um10.fillna(0, inplace=True)\n",
    "    user_merchant['um14'] = user_merchant.um10 / user_merchant.um9\n",
    "    \n",
    "    # 用户消费过的商家数量占接触过的商家总数量的比值\n",
    "    # um15\n",
    "    user_merchant.um9.fillna(0, inplace=True)\n",
    "    user_merchant['um15'] = user_merchant.um9 / user_merchant.um12\n",
    "    \n",
    "    dataset = pd.merge(dataset, user_merchant, how='left', on=['User_id', 'Merchant_id'])\n",
    "    del user_merchant\n",
    "    \n",
    "    # ========================================\n",
    "    # ====== other feature 字段 ==============\n",
    "    # ========================================\n",
    "    # 用户领取的所有优惠券数目(label窗)\n",
    "    # o1\n",
    "    t = dataset[['User_id']]\n",
    "    t['o1'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户领取的特定优惠券数目\n",
    "    # o2\n",
    "    t = dataset[['User_id', 'Coupon_id']]\n",
    "    t['o2'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    \n",
    "    # 用户当天领取的优惠券数目\n",
    "    # o6\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t['o6'] = 1\n",
    "    t = t.groupby(['User_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Date_received'])\n",
    "\n",
    "    # 用户当天领取的特定优惠券数目\n",
    "    # o7\n",
    "    t = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t['o7'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "    \n",
    "    # 是否是当月领取相同优惠券中的第一张、最后一张\n",
    "    # o13, o14\n",
    "    t = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t.Date_received = t.Date_received.astype('str')\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).Date_received.agg(lambda x: ':'.join(x)).reset_index()\n",
    "    t['receive_number'] = t.Date_received.apply(lambda s: len(s.split(':')))\n",
    "    t = t[t.receive_number > 1]\n",
    "    t['max_date_received'] = t.Date_received.apply(lambda s: max([int(d) for d in s.split(':')]))\n",
    "    t['min_date_received'] = t.Date_received.apply(lambda s: min([int(d) for d in s.split(':')]))\n",
    "    t = t[['User_id', 'Coupon_id', 'max_date_received', 'min_date_received']]\n",
    "\n",
    "    t1 = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t1 = pd.merge(t1, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    t1['o13'] = t1.max_date_received.astype('float') - t1.Date_received.astype('float')\n",
    "    t1['o14'] = t1.Date_received.astype('float') - t1.min_date_received.astype('float')\n",
    "\n",
    "    t1.o13 = t1.o13.apply(is_firstlastone)\n",
    "    t1.o14 = t1.o14.apply(is_firstlastone)\n",
    "    t1 = t1[['User_id', 'Coupon_id', 'Date_received', 'o13', 'o14']]\n",
    "    dataset = pd.merge(dataset, t1, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "    \n",
    "    # 商家有交集的用户数目\n",
    "    # o17\n",
    "    t = dataset[['Merchant_id', 'User_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('Merchant_id').User_id.agg('count').reset_index(name='o17')\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Merchant_id')\n",
    "    \n",
    "    # 商家发出的所有优惠券数目\n",
    "    # o18\n",
    "    t = dataset[['Merchant_id', 'Coupon_id']]\n",
    "    t = t.groupby('Merchant_id').Coupon_id.agg('count').reset_index(name='o18')\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Merchant_id')\n",
    "    \n",
    "    # 商家发出的所有优惠券种类数目\n",
    "    # o19\n",
    "    t = dataset[['Merchant_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('Merchant_id').Coupon_id.agg('count').reset_index(name='o19')\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Merchant_id')\n",
    "    \n",
    "    # 用户领取该商家的所有优惠券数目\n",
    "    # o20\n",
    "    t = dataset[['User_id', 'Merchant_id']]\n",
    "    t['o20'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "    \n",
    "    # 用户在此次优惠券之后还领取了多少优惠券\n",
    "    # o21\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t = t.groupby('User_id').Date_received.agg(lambda x: ':'.join(x)).reset_index(name='all_date_received')\n",
    "    t1 = dataset[['User_id', 'Date_received']]\n",
    "    t1 = pd.merge(t1, t, how='left', on='User_id')\n",
    "    t1['o21'] = 0\n",
    "    t1 = t1[t1.all_date_received.str.contains(':')]\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "    t1.o21 = list(map(lambda x, y: getO21(x, y), t1.Date_received, t1.all_date_received))\n",
    "    dataset = pd.merge(dataset, t1[['User_id', 'Date_received', 'o21']], how='left', on=['User_id', 'Date_received'])\n",
    "    \n",
    "    # 用户在此次优惠券之后还领取了多少该优惠券\n",
    "    # o22\n",
    "    t = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).Date_received.agg(lambda x: ':'.join(x)).reset_index(name='all_date_received')\n",
    "    t1 = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t1 = pd.merge(t1, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    t1['o22'] = 0\n",
    "    t1 = t1[t1.all_date_received.str.contains(':')]\n",
    "    t1.drop_duplicates(inplace=True)\n",
    "    t1.o22 = list(map(lambda x, y: getO21(x, y), t1.Date_received, t1.all_date_received))\n",
    "    dataset = pd.merge(dataset, t1[['User_id', 'Coupon_id', 'Date_received', 'o22']], how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "    \n",
    "    # 用户有交集的商家数目\n",
    "    # o23\n",
    "    t = dataset[['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='o23')\n",
    "    dataset = pd.merge(dataset, t, how='left', on='User_id')\n",
    "    \n",
    "    # ========================================\n",
    "    # ====== user coupon 字段 ================\n",
    "    # =======================================\n",
    "    # 对label窗里的user_coupon，特征窗里用户领取过该coupon几次\n",
    "    # uc1\n",
    "    t = receive_coupon[['User_id', 'Coupon_id']]\n",
    "    t['uc1'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    \n",
    "    # 对label窗里的user_coupon，特征窗里用户用该coupon消费过几次\n",
    "    # uc2\n",
    "    t = consume_use_coupon[['User_id', 'Coupon_id']]\n",
    "    t['uc2'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    \n",
    "    # 对label窗里的user_coupon，特征窗里用户对该coupon的核销率\n",
    "    # uc3\n",
    "    dataset.uc2.fillna(0, inplace=True)\n",
    "    dataset['uc3'] = dataset.uc2 / dataset.uc1\n",
    "    \n",
    "    del t, t1, consume_use_coupon, consume_common, receive_coupon_not_consume, receive_coupon, consume\n",
    "    print('...get offline feature complete...')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e6919264fef7978f2f0ed3b4cea0cb0f475ae53a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_online_feature(dataset, feature):\n",
    "\n",
    "    \"\"\"\n",
    "    4. 提取线上特征\n",
    "    \"\"\"\n",
    "    \n",
    "    # 用户线上购买次数\n",
    "    # on_u4\n",
    "    t = feature[feature.Action == 1][['User_id']]\n",
    "    t['on_u4'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上优惠券核销次数\n",
    "    # on_u9\n",
    "    t = feature[(feature.Date != 'null') & (feature.Action == 2)][['User_id']]\n",
    "    t['on_u9'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上用fixed购买的总次数\n",
    "    # on_u15\n",
    "    t = feature[(feature.Coupon_id == 'fixed') & (feature.Action == 1)][['User_id']]\n",
    "    t['on_u15'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='User_id')\n",
    "    \n",
    "    # 用户线上领取次数\n",
    "    # on_u6\n",
    "    t = feature[(feature.Coupon_id != 'null') & (feature.Coupon_id != 'fixed')][['User_id']]\n",
    "    t['on_u6'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上有发生购买的merchant个数\n",
    "    # on_u16\n",
    "    t = feature[feature.Action == 1][['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='on_u16')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上有action的merchant个数\n",
    "    # on_u16\n",
    "    t = feature[['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='on_u17')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # online_buy_use_coupon_fixed\n",
    "    # on_u17\n",
    "    dataset.on_u9.fillna(0, inplace=True)\n",
    "    dataset.on_u15.fillna(0, inplace=True)\n",
    "    dataset['on_u17'] = dataset.on_u9 + dataset.on_u15\n",
    "    \n",
    "    # online_buy_use_coupon_rate\n",
    "    # on_u18\n",
    "    dataset['on_u18'] = dataset.on_u9 / dataset.on_u4\n",
    "    \n",
    "    # online_buy_use_fixed_rate\n",
    "    # on_u19\n",
    "    dataset['on_u19'] = dataset.on_u15 / dataset.on_u4\n",
    "    \n",
    "    # online_buy_use_coupon_fixed_rate\n",
    "    # on_u20\n",
    "    dataset.on_u17.fillna(0, inplace=True)\n",
    "    dataset['on_u20'] = dataset.on_u17 / dataset.on_u4\n",
    "    \n",
    "    # online_coupon_transform_rate\n",
    "    # on_u21\n",
    "    dataset['on_u21'] = dataset.on_u9 / dataset.on_u6\n",
    "    \n",
    "    del t\n",
    "    print('...get online feature complete...')   \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ad135d310686d4e221fce56e06d2f1141f191055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "(136099, 102) (256808, 102) (112803, 101) (112803, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = get_offline_feature(dataset1, off_feature1)\n",
    "dataset1 = get_online_feature(dataset1, on_feature1)\n",
    "dataset2 = get_offline_feature(dataset2, off_feature2)\n",
    "dataset2 = get_online_feature(dataset2, on_feature2)\n",
    "dataset3 = get_offline_feature(dataset3, off_feature3)\n",
    "dataset3 = get_online_feature(dataset3, on_feature3)\n",
    "\n",
    "del off_feature1, off_feature2, off_feature3\n",
    "del on_feature1, on_feature2, on_feature3\n",
    "\n",
    "# one-hot处理\n",
    "weekday_dummies = pd.get_dummies(dataset1.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset1 = pd.concat([dataset1, weekday_dummies], axis=1)\n",
    "weekday_dummies = pd.get_dummies(dataset2.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset2 = pd.concat([dataset2, weekday_dummies], axis=1)\n",
    "weekday_dummies = pd.get_dummies(dataset3.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset3 = pd.concat([dataset3, weekday_dummies], axis=1)\n",
    "\n",
    "day_dummies = pd.get_dummies(dataset1.day)\n",
    "day_dummies.columns = ['day_' + str(i) for i in range(1, 31)]\n",
    "dataset1 = pd.concat([dataset1, day_dummies], axis=1)\n",
    "day_dummies = pd.get_dummies(dataset2.day)\n",
    "day_dummies.columns = ['day_' + str(i) for i in range(1, 32)]\n",
    "dataset2 = pd.concat([dataset2, day_dummies], axis=1)\n",
    "dataset2.drop(columns='day_31', inplace=True)\n",
    "day_dummies = pd.get_dummies(dataset3.day)\n",
    "day_dummies.columns = ['day_' + str(i) for i in range(1, 32)]\n",
    "dataset3 = pd.concat([dataset3, day_dummies], axis=1)\n",
    "dataset3.drop(columns='day_31', inplace=True)\n",
    "\n",
    "# dataset去重\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "Submission = dataset3[['User_id', 'Coupon_id', 'Date_received']]\n",
    "\n",
    "# 删掉没用的列\n",
    "drop_columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Date_received', 'day', 'weekday']\n",
    "dataset1.drop(columns=drop_columns, inplace=True)\n",
    "dataset1.Distance.replace('null', -999, inplace=True)\n",
    "dataset1.Distance = dataset1.Distance.astype(int)\n",
    "dataset1.Distance.replace(-999, np.nan, inplace=True)\n",
    "dataset2.drop(columns=drop_columns, inplace=True)\n",
    "dataset2.Distance.replace('null', -999, inplace=True)\n",
    "dataset2.Distance = dataset2.Distance.astype(int)\n",
    "dataset2.Distance.replace(-999, np.nan, inplace=True)\n",
    "dataset3.drop(columns=drop_columns, inplace=True)\n",
    "dataset3.Distance.replace('null', -999, inplace=True)\n",
    "dataset3.Distance = dataset3.Distance.astype(int)\n",
    "dataset3.Distance.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "print(dataset1.shape, dataset2.shape, dataset3.shape, Submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "222b915627cc1c463911afd826f3774cbf768a9e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset1.to_csv('../dataset/dataset1.csv', index=False)\n",
    "dataset2.to_csv('../dataset/dataset2.csv', index=False)\n",
    "dataset3.to_csv('../dataset/dataset3.csv', index=False)\n",
    "Submission.to_csv('../dataset/Submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
