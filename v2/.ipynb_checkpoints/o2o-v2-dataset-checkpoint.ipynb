{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c95603c932daefc690377e27525dcee2d28777df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp\n",
    "%matplotlib inline\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger_output = logging.FileHandler('o2o-v2-dataset.log', mode='a')\n",
    "logger_output.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\"[%(asctime)s]: %(message)s\")\n",
    "logger_output.setFormatter(formatter)\n",
    "logger.addHandler(logger_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "fe04bdfccbb63a9d5995d224b898734989fe9cb7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDiscount_rate(s):\n",
    "    if s == 'null':\n",
    "        return 1\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return 1 - float(temp[1]) / float(temp[0])\n",
    "    else:\n",
    "        return float(s)\n",
    "    \n",
    "    \n",
    "def getIsManjian(s):\n",
    "    if ':' in s:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def getDiscountMan(s):\n",
    "    if s == 'null':\n",
    "        return np.nan\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return float(temp[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def getDiscountJian(s):\n",
    "    if s == 'null':\n",
    "        return np.nan\n",
    "    elif ':' in s:\n",
    "        temp = s.split(':')\n",
    "        return float(temp[1])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def get_date_gap(s):\n",
    "    s = s.split(':')\n",
    "    return (date(int(s[0][0:4]), int(s[0][4:6]), int(s[0][6:8])) - date(int(s[1][0:4]), int(s[1][4:6]), int(s[1][6:8]))).days\n",
    "\n",
    "\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if 'null' in s:\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]), int(s[0][4:6]), int(s[0][6:8])) - date(int(s[1][0:4]), int(s[1][4:6]), int(s[1][6:8]))).days <= 15:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def is_firstlastone(x):\n",
    "    if x == 0:\n",
    "        return 1\n",
    "    elif x > 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1  #those only receive once\n",
    "    \n",
    "\n",
    "def getO21(x, y):\n",
    "    y = y.split(':')\n",
    "    count = 0\n",
    "    for el in y:\n",
    "        if el >= x:\n",
    "            count += 1\n",
    "    return count - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "364e92f239e54305fa338ea2498e3c447b5e7b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113640, 7) (1754884, 8) (11429826, 7)\n",
      "(137167, 8) (995240, 8) (5982320, 7)\n",
      "(258446, 8) (812779, 8) (6098712, 7)\n",
      "(113640, 7) (1036975, 8) (7431432, 7)\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "off_test = pd.read_csv('../input/ccf_offline_stage1_test_revised.csv', keep_default_na=False)\n",
    "off_train = pd.read_csv('../input/ccf_offline_stage1_train.csv', keep_default_na=False)\n",
    "on_train = pd.read_csv('../input/ccf_online_stage1_train.csv', keep_default_na=False)\n",
    "\n",
    "off_test['discount_rate'] = off_test.Discount_rate.apply(getDiscount_rate)\n",
    "off_train['discount_rate'] = off_train.Discount_rate.apply(getDiscount_rate)\n",
    "\n",
    "print(off_test.shape, off_train.shape, on_train.shape)\n",
    "\n",
    "# 分割数据集\n",
    "# dateset3: 20160701~20160731 (113640), features3 from 20160315~20160630\n",
    "# dateset2: 20160515~20160615 (258446), features2 from 20160201~20160514  \n",
    "# dateset1: 20160414~20160514 (138303), features1 from 20160101~20160413\n",
    "# for dataset1\n",
    "start, end = '20160414', '20160514'\n",
    "dataset1 = off_train[(start <= off_train.Date_received) & (off_train.Date_received <= end)]\n",
    "# 提取label\n",
    "dataset1['label'] = dataset1.Date_received + ':' + dataset1.Date\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(columns=['Date'], inplace=True)\n",
    "start, end = '20160101', '20160413'\n",
    "off_feature1 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature1 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "# for dateset2\n",
    "start, end = '20160515', '20160615'\n",
    "dataset2 = off_train[(start <= off_train.Date_received) & (off_train.Date_received <= end)]\n",
    "# 提取label\n",
    "dataset2['label'] = dataset2.Date_received + ':' + dataset2.Date\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(columns=['Date'], inplace=True)\n",
    "start, end = '20160201', '20160514'\n",
    "off_feature2 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature2 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "# for dataset3\n",
    "dataset3 = off_test.copy()\n",
    "dataset3.Coupon_id = dataset3.Coupon_id.astype(str)\n",
    "dataset3.Date_received = dataset3.Date_received.astype(str)\n",
    "start, end = '20160315', '20160630'\n",
    "off_feature3 = off_train[((start <= off_train.Date) & (off_train.Date <= end)) | ((off_train.Date == 'null') & (start <= off_train.Date_received) & (off_train.Date_received <= end))]\n",
    "on_feature3 = on_train[((start <= on_train.Date) & (on_train.Date <= end)) | ((on_train.Date == 'null') & (start <= on_train.Date_received) & (on_train.Date_received <= end))]\n",
    "\n",
    "del off_test, off_train, on_train\n",
    "print(dataset1.shape, off_feature1.shape, on_feature1.shape)\n",
    "print(dataset2.shape, off_feature2.shape, on_feature2.shape)\n",
    "print(dataset3.shape, off_feature3.shape, on_feature3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "cf9e5e1a9351446d7b4f2484b8cc0a2ad1d6caab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_offline_feature(dataset, feature):\n",
    "    \n",
    "    \"\"\"\n",
    "    3. 提取线下特征\n",
    "    \"\"\"\n",
    "\n",
    "    # weekday\n",
    "    dataset['weekday'] = dataset.Date_received.astype('str').apply(lambda x: date(int(x[0: 4]), int(x[4: 6]), int(x[6: 8])).weekday() + 1)\n",
    "    # is_weekend\n",
    "    dataset['is_weekend'] = dataset.weekday.apply(lambda x: 1 if x in (6, 7) else 0)\n",
    "    # day\n",
    "    dataset['day'] = dataset.Date_received.astype('str').apply(lambda x: int(x[6:8]))\n",
    "    # ========================================================================================================================\n",
    "    # ===================================== user 字段特征 ====================================================================\n",
    "    # ========================================================================================================================\n",
    "\n",
    "    user = feature[['User_id']]\n",
    "    user.drop_duplicates(inplace=True)\n",
    "\n",
    "    consume_use_coupon = feature[(feature.Coupon_id != 'null') & (feature.Date != 'null')]  #用户领取优惠券消费信息\n",
    "    consume_common = feature[(feature.Coupon_id == 'null') & (feature.Date != 'null')]  #用户普通消费信息\n",
    "    receive_coupon_not_consume = feature[(feature.Coupon_id != 'null') & (feature.Date == 'null')]  #用户领取优惠券但未使用信息\n",
    "    receive_coupon = feature[feature.Coupon_id != 'null']  #用户领取优惠券信息\n",
    "    consume = feature[feature.Date != 'null']  #用户消费信息\n",
    "\n",
    "    # 线下使用优惠券消费的次数\n",
    "    # u1\n",
    "    t = consume_use_coupon[['User_id']]\n",
    "    t['u1'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 线下领取优惠券但没有使用的次数\n",
    "    # u2\n",
    "    t = receive_coupon_not_consume[['User_id']]\n",
    "    t['u2'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 使用优惠券次数与没使用优惠券次数比值\n",
    "    # u3\n",
    "    user['u3'] = user.u1 / user.u2\n",
    "\n",
    "    # 领取优惠券的总次数\n",
    "    # u4\n",
    "    t = receive_coupon[['User_id']]\n",
    "    t['u4'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 优惠券核销率\n",
    "    # u5\n",
    "    user.u1.fillna(0, inplace=True)\n",
    "    user['u5'] = user.u1 / user.u4\n",
    "\n",
    "    # 线下普通消费次数\n",
    "    # u6\n",
    "    t = consume_common[['User_id']]\n",
    "    t['u6'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 一共消费多少次\n",
    "    # u7\n",
    "    t = consume[['User_id']]\n",
    "    t['u7'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户使用优惠券消费占比\n",
    "    # u8\n",
    "    user['u8'] = user.u1 / user.u7\n",
    "\n",
    "    # 线下平均普通消费间隔\n",
    "    # u9\n",
    "    t = consume_common[['User_id', 'Date']]\n",
    "    t = t.groupby('User_id').Date.apply(lambda x: ':'.join(x)).reset_index(name='u9')\n",
    "    t['len'] = t.u9.apply(lambda x: len(x.split(':')) - 1)\n",
    "    t = t[t.len != 0]\n",
    "    t['max_min'] = t.u9.apply(lambda x: max(x.split(':')) + ':' + min(x.split(':')))\n",
    "    t['days'] = t.max_min.apply(get_date_gap)\n",
    "    t.u9 = t.days.astype(float) / t.len\n",
    "    user = pd.merge(user, t[['User_id', 'u9']], how='left', on='User_id')\n",
    "\n",
    "    # 线下平均优惠券消费间隔\n",
    "    # u10\n",
    "    t = consume_use_coupon[['User_id', 'Date']]\n",
    "    t = t.groupby('User_id').Date.apply(lambda x: ':'.join(x)).reset_index(name='u10')\n",
    "    t['len'] = t.u10.apply(lambda x: len(x.split(':')) - 1)\n",
    "    t = t[t.len != 0]\n",
    "    t['max_min'] = t.u10.apply(lambda x: max(x.split(':')) + ':' + min(x.split(':')))\n",
    "    t['days'] = t.max_min.apply(get_date_gap)\n",
    "    t.u10 = t.days.astype(float) / t.len\n",
    "    user = pd.merge(user, t[['User_id', 'u10']], how='left', on='User_id')\n",
    "\n",
    "    # 15天内平均会普通消费几次\n",
    "    # u11\n",
    "    user['u11'] = user.u9 / 15\n",
    "\n",
    "    # 15天内平均会优惠券消费几次\n",
    "    # u12\n",
    "    user['u12'] = user.u10 / 15\n",
    "\n",
    "    # 领取优惠券到使用优惠券的平均间隔时间\n",
    "    # u13\n",
    "    t = consume_use_coupon[['User_id', 'Date_received', 'Date']]\n",
    "    t['date_date_received'] = t.Date + ':' + t.Date_received\n",
    "    t['u13'] = t.date_date_received.apply(get_date_gap)\n",
    "    t = t[['User_id', 'u13']].groupby('User_id').agg('mean').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 在15天内使用掉优惠券的值的大小？\n",
    "    # u14\n",
    "    user['u14'] = user.u13 / 15\n",
    "\n",
    "    # 领取优惠券到使用优惠券间隔小于15天的次数\n",
    "    # u15\n",
    "    t = consume_use_coupon[['User_id', 'Date_received', 'Date']]\n",
    "    t['date_date_received'] = t.Date + ':' + t.Date_received\n",
    "    t['u15'] = t.date_date_received.apply(get_date_gap)\n",
    "    t = t[t.u15 < 15][['User_id', 'u15']].groupby('User_id').agg('count').reset_index()\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以使用优惠券的次数\n",
    "    # u16\n",
    "    user['u16'] = user.u15 / user.u1\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以领取优惠券的总次数\n",
    "    # u17\n",
    "    user['u17'] = user.u15 / user.u4\n",
    "\n",
    "    # 用户15天使用掉优惠券的次数除以领取优惠券未消费的次数\n",
    "    # u18\n",
    "    user['u18'] = user.u15 / user.u2\n",
    "\n",
    "    # 消费优惠券的平均折扣率\n",
    "    # u19\n",
    "    t = consume_use_coupon[['User_id', 'discount_rate']].groupby('User_id').discount_rate.agg('mean').reset_index(name='u19')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券的最低消费折扣率\n",
    "    # u20\n",
    "    t = consume_use_coupon[['User_id', 'discount_rate']].groupby('User_id').discount_rate.agg('min').reset_index(name='u20')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券的最高消费折扣率\n",
    "    # u21\n",
    "    t = consume_use_coupon[['User_id', 'discount_rate']].groupby('User_id').discount_rate.agg('max').reset_index(name='u21')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户领取优惠券不同优惠券数量\n",
    "    # u24\n",
    "    t = receive_coupon[['User_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Coupon_id.agg('count').reset_index(name='u24')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销优惠券不同优惠券数量\n",
    "    # u25\n",
    "    t = consume_use_coupon[['User_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Coupon_id.agg('count').reset_index(name='u25')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户核销过优惠券的不同优惠券数量占所有不同优惠券的比重\n",
    "    # u26\n",
    "    user['u26'] = user.u25 / user.u24\n",
    "\n",
    "    # 用户平均每种优惠券核销多少张\n",
    "    # u27\n",
    "    user['u27'] = user.u1 / user.u24\n",
    "    \n",
    "    # 用户优惠券消费的平均距离\n",
    "    # u31\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('mean').reset_index(name='u31')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户优惠券消费的最小距离\n",
    "    # u32\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('min').reset_index(name='u32')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户优惠券消费的最大距离\n",
    "    # u33\n",
    "    t = consume_use_coupon[['User_id', 'Distance']]\n",
    "    t.replace('null', -1, inplace=True)\n",
    "    t.Distance = t.Distance.astype('int')\n",
    "    t.replace(-1, np.nan, inplace=True)\n",
    "    t = t.groupby('User_id').Distance.agg('max').reset_index(name='u33')\n",
    "    user = pd.merge(user, t, how='left', on='User_id')\n",
    "\n",
    "    dataset = pd.merge(dataset, user, how='left', on='User_id')\n",
    "    del user\n",
    "\n",
    "    # ============================================================================================================================\n",
    "    # ================================= user_coupon 双字段特征 ===================================================================\n",
    "    # ============================================================================================================================\n",
    "    user_coupon = feature[['User_id', 'Coupon_id']]\n",
    "    user_coupon.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 用户核销过的不同优惠券数量\n",
    "    # uc1\n",
    "    t = consume_use_coupon[['User_id', 'Coupon_id']]\n",
    "    t['uc1'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    user_coupon = pd.merge(user_coupon, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "\n",
    "    # 用户领取所有不同优惠券数量\n",
    "    # uc2\n",
    "    t = receive_coupon[['User_id', 'Coupon_id']]\n",
    "    t['uc2'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    user_coupon = pd.merge(user_coupon, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "\n",
    "    # 用户核销过的不同优惠券数量占所有不同优惠券的比重\n",
    "    # uc3\n",
    "    user_coupon.uc1.fillna(0, inplace=True)\n",
    "    user_coupon['uc3'] = user_coupon.uc1 / user_coupon.uc2\n",
    "\n",
    "    dataset = pd.merge(dataset, user_coupon, how='left', on=['User_id', 'Coupon_id'])\n",
    "    del user_coupon\n",
    "\n",
    "    # # ==========================================================================================================================\n",
    "    # # ================================ user_merchant ===========================================================================\n",
    "    # # ==========================================================================================================================\n",
    "    user_merchant = feature[['User_id', 'Merchant_id']]\n",
    "    user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 用户领取商家的优惠券次数\n",
    "    # um4\n",
    "    t = receive_coupon[['User_id', 'Merchant_id']]\n",
    "    t['um4'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后不核销次数\n",
    "    # um5\n",
    "    t = receive_coupon_not_consume[['User_id', 'Merchant_id']]\n",
    "    t['um5'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后核销次数\n",
    "    # um6\n",
    "    t = consume_use_coupon[['User_id', 'Merchant_id']]\n",
    "    t['um6'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取商家的优惠券后核销率\n",
    "    # um7\n",
    "    user_merchant['um7'] = user_merchant.um6 / user_merchant.um4\n",
    "\n",
    "    # 用户对每个商家的不核销次数占用户总的不核销次数的比重\n",
    "    # um8\n",
    "    t = receive_coupon_not_consume[['User_id']]\n",
    "    t['um8'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id'])\n",
    "    user_merchant.um5.fillna(0, inplace=True)\n",
    "    user_merchant.um8 = user_merchant.um5 / user_merchant.um8\n",
    "\n",
    "    # 用户在商店总共消费过几次\n",
    "    # um9\n",
    "    t = consume[['User_id', 'Merchant_id']]\n",
    "    t['um9'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户在商店普通消费次数\n",
    "    # um10\n",
    "    t = consume_common[['User_id', 'Merchant_id']]\n",
    "    t['um10'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    user_merchant = pd.merge(user_merchant, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户当天在此商店领取的优惠券数目\n",
    "    # um11\n",
    "    t = dataset[dataset.Date_received != 'null'][['User_id', 'Merchant_id', 'Date_received']]\n",
    "    t['um11'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Merchant_id', 'Date_received'])\n",
    "\n",
    "    dataset = pd.merge(dataset, user_merchant, how='left', on=['User_id', 'Merchant_id'])\n",
    "    del user_merchant\n",
    "\n",
    "    # =========================================================================================================================\n",
    "    # ================================ user_discount_rate =====================================================================\n",
    "    # =========================================================================================================================\n",
    "    user_discount = feature[['User_id', 'Discount_rate']]\n",
    "    user_discount.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 不同打折优惠券领取次数\n",
    "    # ud1\n",
    "    t = receive_coupon[['User_id', 'Discount_rate']]\n",
    "    t['ud1'] = 1\n",
    "    t = t.groupby(['User_id', 'Discount_rate']).agg('sum').reset_index()\n",
    "    user_discount = pd.merge(user_discount, t, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同打折优惠券使用次数\n",
    "    # ud2\n",
    "    t = consume_use_coupon[['User_id', 'Discount_rate']]\n",
    "    t['ud2'] = 1\n",
    "    t = t.groupby(['User_id', 'Discount_rate']).agg('sum').reset_index()\n",
    "    user_discount = pd.merge(user_discount, t, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同打折优惠券不使用次数\n",
    "    # ud3\n",
    "    t = receive_coupon_not_consume[['User_id', 'Discount_rate']]\n",
    "    t['ud3'] = 1\n",
    "    t = t.groupby(['User_id', 'Discount_rate']).agg('sum').reset_index()\n",
    "    user_discount = pd.merge(user_discount, t, how='left', on=['User_id', 'Discount_rate'])\n",
    "\n",
    "    # 不同打折优惠券使用率\n",
    "    # ud4\n",
    "    user_discount.ud2.fillna(0, inplace=True)\n",
    "    user_discount['ud4'] = user_discount.ud2 / user_discount.ud1\n",
    "\n",
    "    dataset = pd.merge(dataset, user_discount, how='left', on=['User_id', 'Discount_rate'])\n",
    "    del user_discount\n",
    "\n",
    "    # ===========================================================================================================================\n",
    "    # ================================ merchant 字段特征 ========================================================================\n",
    "    # ===========================================================================================================================\n",
    "    merchant = feature[['Merchant_id']]\n",
    "    merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 商家被消费次数\n",
    "    # m1\n",
    "    t = consume[['Merchant_id']]\n",
    "    t['m1'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被优惠券消费次数\n",
    "    # m2\n",
    "    t = consume_use_coupon[['Merchant_id']]\n",
    "    t['m2'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "\n",
    "    # 商户被普通消费次数\n",
    "    # m3\n",
    "    t = consume_common[['Merchant_id']]\n",
    "    t['m3'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商户优惠券被领取次数\n",
    "    # m4\n",
    "    t = receive_coupon[['Merchant_id']]\n",
    "    t['m4'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券被领取后的核销率\n",
    "    # m5 = m2 / m4\n",
    "    merchant['m5'] = merchant.m2 / merchant.m4\n",
    "\n",
    "    # 商家优惠券被领取后不核销次数\n",
    "    # m6\n",
    "    t = receive_coupon_not_consume[['Merchant_id']]\n",
    "    t['m6'] = 1\n",
    "    t = t.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商户当天优惠券被领取次数\n",
    "    # m7\n",
    "    t = dataset[dataset.Date_received != 'null'][['Merchant_id', 'Date_received']]\n",
    "    t['m7'] = 1\n",
    "    t = t.groupby(['Merchant_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id', 'Date_received'])\n",
    "\n",
    "    # 商户当天优惠券领取人数\n",
    "    # m8\n",
    "    t = dataset[dataset.Date_received != 'null'][['Merchant_id', 'User_id', 'Date_received']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby(['Merchant_id', 'Date_received']).User_id.agg('count').reset_index(name='m8')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id', 'Date_received'])\n",
    "\n",
    "    # 商家优惠券核销的平均消费折扣率\n",
    "    # m9\n",
    "    t = consume_use_coupon[['Merchant_id', 'discount_rate']]\n",
    "    t = t.groupby('Merchant_id').discount_rate.agg('mean').reset_index(name='m9')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销的最小消费折扣率\n",
    "    # m10\n",
    "    t = consume_use_coupon[['Merchant_id', 'discount_rate']]\n",
    "    t = t.groupby('Merchant_id').discount_rate.agg('min').reset_index(name='m10')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销的最大消费折扣率\n",
    "    # m11\n",
    "    t = consume_use_coupon[['Merchant_id', 'discount_rate']]\n",
    "    t = t.groupby('Merchant_id').discount_rate.agg('max').reset_index(name='m11')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券核销的不同的用户数量\n",
    "    # m12\n",
    "    t = consume_use_coupon[['Merchant_id', 'User_id']]\n",
    "    t = t.groupby('Merchant_id').User_id.agg('count').reset_index(name='m12')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家优惠券领取的不同的用户数量\n",
    "    # m13\n",
    "    t = receive_coupon[['Merchant_id', 'User_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('Merchant_id').User_id.agg('count').reset_index(name='m13')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 核销商家优惠券的不同用户数量其占领取不同的用户比重\n",
    "    # m14 = m12 / m13\n",
    "    merchant['m14'] = merchant.m12 / merchant.m13\n",
    "\n",
    "    # 商家优惠券平均每个用户核销多少张\n",
    "    # m15 = m2 / m13\n",
    "    merchant['m15'] = merchant.m2 / merchant.m13\n",
    "\n",
    "    # 商家被核销过的不同优惠券数量\n",
    "    # m16\n",
    "    t = consume_use_coupon[['Merchant_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('Merchant_id').Coupon_id.agg('count').reset_index(name='m16')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家领取过的不同优惠券数量\n",
    "    # m17\n",
    "    t = receive_coupon[['Merchant_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('Merchant_id').Coupon_id.agg('count').reset_index(name='m17')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销过的不同优惠券数量占所有领取过的不同优惠券数量的比重\n",
    "    # m18 = m16 / m17\n",
    "    merchant['m18'] = merchant.m16 / merchant.m17\n",
    "\n",
    "    # 商家被核销优惠券的平均时间\n",
    "    # m19\n",
    "    t = consume_use_coupon[['Merchant_id', 'Date']]\n",
    "    t = t.groupby('Merchant_id').Date.apply(lambda x: ':'.join(x)).reset_index(name='m19')\n",
    "    t['len'] = t.m19.apply(lambda x: len(x.split(':')) - 1)\n",
    "    t = t[t.len != 0]\n",
    "    t['max_min'] = t.m19.apply(lambda x: max(x.split(':')) + ':' + min(x.split(':')))\n",
    "    t['days'] = t.max_min.apply(get_date_gap)\n",
    "    t.m19 = t.days.astype(float) / t.len\n",
    "    merchant = pd.merge(merchant, t[['Merchant_id', 'm19']], how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家平均距离\n",
    "    # m20\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('mean').reset_index(name='m20')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最小距离\n",
    "    # m21\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('min').reset_index(name='m21')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    # 商家被核销优惠券中的用户-商家最大距离\n",
    "    # m22\n",
    "    t = consume_use_coupon[consume_use_coupon.Distance != 'null'][['Merchant_id', 'Distance']]\n",
    "    t.Distance = t.Distance.astype(int)\n",
    "    t = t.groupby('Merchant_id').Distance.agg('max').reset_index(name='m22')\n",
    "    merchant = pd.merge(merchant, t, how='left', on='Merchant_id')\n",
    "\n",
    "    dataset = pd.merge(dataset, merchant, how='left', on='Merchant_id')\n",
    "    del merchant\n",
    "\n",
    "    # # ==========================================================================================================================\n",
    "    # # ================================ coupon 字段特征 =========================================================================\n",
    "    # # ==========================================================================================================================\n",
    "    coupon = receive_coupon[['Coupon_id']]\n",
    "    coupon.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 此优惠券一共发行多少张\n",
    "    # c1\n",
    "    t = receive_coupon[['Coupon_id']]\n",
    "    t['c1'] = 1\n",
    "    t = t.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    coupon = pd.merge(coupon, t, how='left', on='Coupon_id')\n",
    "\n",
    "    # 此优惠券一共被使用多少张\n",
    "    # c2\n",
    "    t = consume_use_coupon[['Coupon_id']]\n",
    "    t['c2'] = 1\n",
    "    t = t.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    coupon = pd.merge(coupon, t, how='left', on='Coupon_id')\n",
    "\n",
    "    # 优惠券使用率\n",
    "    # c3\n",
    "    coupon['c3'] = coupon.c2 / coupon.c1\n",
    "\n",
    "    # 没有使用的数目\n",
    "    # c4\n",
    "    t = receive_coupon_not_consume[['Coupon_id']]\n",
    "    t['c4'] = 1\n",
    "    t = t.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    coupon = pd.merge(coupon, t, how='left', on='Coupon_id')\n",
    "\n",
    "    # 此优惠券在当天发行了多少张\n",
    "    # c5\n",
    "    t = dataset[dataset.Coupon_id != 'null'][['Coupon_id', 'Date_received']]\n",
    "    t['c5'] = 1\n",
    "    t = t.groupby(['Coupon_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Coupon_id', 'Date_received'])\n",
    "\n",
    "    # 优惠券类型(直接优惠为0, 满减为1)\n",
    "    # c6\n",
    "    dataset['c6'] = dataset.Discount_rate.apply(getIsManjian)\n",
    "\n",
    "    # 不同打折优惠券领取次数\n",
    "    # c7\n",
    "    t = receive_coupon[['Discount_rate']]\n",
    "    t['c7'] = 1\n",
    "    t = t.groupby('Discount_rate').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券使用次数\n",
    "    # c8\n",
    "    t = consume_use_coupon[['Discount_rate']]\n",
    "    t['c8'] = 1\n",
    "    t = t.groupby('Discount_rate').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券不使用次数\n",
    "    # c9\n",
    "    t = receive_coupon_not_consume[['Discount_rate']]\n",
    "    t['c9'] = 1\n",
    "    t = t.groupby('Discount_rate').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='Discount_rate')\n",
    "\n",
    "    # 不同打折优惠券使用率\n",
    "    # c10 = c8 / c7\n",
    "    dataset['c10'] = dataset.c8 / dataset.c7\n",
    "\n",
    "    # 优惠券核销平均时间\n",
    "    # c11\n",
    "    t = consume_use_coupon[['Coupon_id', 'Date']]\n",
    "    t = t.groupby('Coupon_id').Date.apply(lambda x: ':'.join(x)).reset_index(name='c11')\n",
    "    t['len'] = t.c11.apply(lambda x: len(x.split(':')) - 1)\n",
    "    t = t[t.len != 0]\n",
    "    t['max_min'] = t.c11.apply(lambda x: max(x.split(':')) + ':' + min(x.split(':')))\n",
    "    t['days'] = t.max_min.apply(get_date_gap)\n",
    "    t.c11 = t.days.astype(float) / t.len\n",
    "    coupon = pd.merge(coupon, t[['Coupon_id', 'c11']], how='left', on='Coupon_id')\n",
    "\n",
    "    dataset = pd.merge(dataset, coupon, how='left', on='Coupon_id')\n",
    "    del coupon\n",
    "\n",
    "    # ==========================================================================================================================\n",
    "    # ================================ other feature ===========================================================================\n",
    "    # ==========================================================================================================================\n",
    "    # 用户领取的所有优惠券数目(label窗)\n",
    "    # o1\n",
    "    t = dataset[['User_id']]\n",
    "    t['o1'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='User_id')\n",
    "\n",
    "    # 用户领取的特定优惠券数目\n",
    "    # o2\n",
    "    t = dataset[['User_id', 'Coupon_id']]\n",
    "    t['o2'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "\n",
    "    # 用户下一次领取的平均时间间隔\n",
    "    # o3\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t = t.groupby('User_id').Date_received.apply(lambda x: ':'.join(x)).reset_index(name='o3')\n",
    "    t['len'] = t.o3.apply(lambda x: len(x.split(':')) - 1)\n",
    "    t = t[t.len != 0]\n",
    "    t['max_min'] = t.o3.apply(lambda x: max(x.split(':')) + ':' + min(x.split(':')))\n",
    "    t['days'] = t.max_min.apply(get_date_gap)\n",
    "    t.o3 = t.days.astype(float) / t.len\n",
    "    dataset = pd.merge(dataset, t[['User_id', 'o3']], how='left', on=['User_id'])\n",
    "\n",
    "    # 用户领取特定商家的优惠券数目\n",
    "    # o4\n",
    "    t = dataset[['User_id', 'Merchant_id']]\n",
    "    t['o4'] = 1\n",
    "    t = t.groupby(['User_id', 'Merchant_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Merchant_id'])\n",
    "\n",
    "    # 用户领取的不同商家数目\n",
    "    # o5\n",
    "    t = dataset[['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby(['User_id']).Merchant_id.agg('count').reset_index(name='o5')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "\n",
    "    # 用户当天领取的优惠券数目\n",
    "    # o6\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t['o6'] = 1\n",
    "    t = t.groupby(['User_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Date_received'])\n",
    "\n",
    "    # 用户当天领取的特定优惠券数目\n",
    "    # o7\n",
    "    t = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t['o7'] = 1\n",
    "    t = t.groupby(['User_id', 'Coupon_id', 'Date_received']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "\n",
    "    # 用户领取的所有优惠券种类数目\n",
    "    # o8\n",
    "    t = dataset[['User_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby(['User_id']).Coupon_id.agg('count').reset_index(name='o8')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "\n",
    "    # 商家被领取的优惠券数目\n",
    "    # o9\n",
    "    t = dataset[['Merchant_id']]\n",
    "    t['o9'] = 1\n",
    "    t = t.groupby(['Merchant_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id'])\n",
    "\n",
    "    # 商家被领取的特定优惠券数目\n",
    "    # o10\n",
    "    t = dataset[['Merchant_id', 'Coupon_id']]\n",
    "    t['o10'] = 1\n",
    "    t = t.groupby(['Merchant_id', 'Coupon_id']).agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id', 'Coupon_id'])\n",
    "\n",
    "    # 商家被多少不同用户领取的数目\n",
    "    # o11\n",
    "    t = dataset[['Merchant_id', 'User_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby(['Merchant_id']).User_id.agg('count').reset_index(name='o11')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id'])\n",
    "\n",
    "    # 商家发行的所有优惠券种类数目\n",
    "    # o12\n",
    "    t = dataset[['Merchant_id', 'Coupon_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby(['Merchant_id']).Coupon_id.agg('count').reset_index(name='o12')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['Merchant_id'])\n",
    "\n",
    "    # 是否是当月领取相同优惠券中的第一张、最后一张\n",
    "    # o13, o14\n",
    "    t = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t.Date_received = t.Date_received.astype('str')\n",
    "    t = t.groupby(['User_id', 'Coupon_id']).Date_received.agg(lambda x: ':'.join(x)).reset_index()\n",
    "    t['receive_number'] = t.Date_received.apply(lambda s: len(s.split(':')))\n",
    "    t = t[t.receive_number > 1]\n",
    "    t['max_date_received'] = t.Date_received.apply(lambda s: max([int(d) for d in s.split(':')]))\n",
    "    t['min_date_received'] = t.Date_received.apply(lambda s: min([int(d) for d in s.split(':')]))\n",
    "    t = t[['User_id', 'Coupon_id', 'max_date_received', 'min_date_received']]\n",
    "\n",
    "    t1 = dataset[['User_id', 'Coupon_id', 'Date_received']]\n",
    "    t1 = pd.merge(t1, t, how='left', on=['User_id', 'Coupon_id'])\n",
    "    t1['o13'] = t1.max_date_received.astype('float') - t1.Date_received.astype('float')\n",
    "    t1['o14'] = t1.Date_received.astype('float') - t1.min_date_received.astype('float')\n",
    "\n",
    "    t1.o13 = t1.o13.apply(is_firstlastone)\n",
    "    t1.o14 = t1.o14.apply(is_firstlastone)\n",
    "    t1 = t1[['User_id', 'Coupon_id', 'Date_received', 'o13', 'o14']]\n",
    "    dataset = pd.merge(dataset, t1, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n",
    "\n",
    "    # 最近一次消费到当前领券的时间间隔\n",
    "    # o15\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t1 = consume[['User_id', 'Date']]\n",
    "    t1 = t1.groupby('User_id').Date.agg('max').reset_index(name='last_consume')\n",
    "    t = pd.merge(t, t1, how='left', on='User_id')\n",
    "    t.last_consume.fillna('null', inplace=True)\n",
    "    t = t[t.last_consume != 'null']\n",
    "    t['o15'] = t.Date_received.astype('str') + ':' + t.last_consume.astype('str')\n",
    "    t.o15 = t.o15.apply(get_date_gap)\n",
    "    dataset = pd.merge(dataset, t[['User_id', 'Date_received', 'o15']], how='left', on=['User_id', 'Date_received'])\n",
    "\n",
    "    # # 最近一次优惠券消费到当前领券的时间间隔\n",
    "    # # o16\n",
    "    t = dataset[['User_id', 'Date_received']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t1 = consume_use_coupon[['User_id', 'Date']]\n",
    "    t1 = t1.groupby('User_id').Date.agg('max').reset_index(name='last_consume')\n",
    "    t = pd.merge(t, t1, how='left', on='User_id')\n",
    "    t.last_consume.fillna('null', inplace=True)\n",
    "    t = t[t.last_consume != 'null']\n",
    "    t['o16'] = t.Date_received.astype('str') + ':' + t.last_consume.astype('str')\n",
    "    t.o16 = t.o16.apply(get_date_gap)\n",
    "    dataset = pd.merge(dataset, t[['User_id', 'Date_received', 'o16']], how='left', on=['User_id', 'Date_received'])\n",
    "\n",
    "    del t, t1, consume_use_coupon, consume_common, receive_coupon_not_consume, receive_coupon, consume\n",
    "    print('...get offline feature complete...')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e6919264fef7978f2f0ed3b4cea0cb0f475ae53a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_online_feature(dataset, feature):\n",
    "\n",
    "    \"\"\"\n",
    "    4. 提取线上特征\n",
    "    \"\"\"\n",
    "    \n",
    "    # 用户线上购买次数\n",
    "    # on_u4\n",
    "    t = feature[feature.Action == 1][['User_id']]\n",
    "    t['on_u4'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上优惠券核销次数\n",
    "    # on_u9\n",
    "    t = feature[(feature.Date != 'null') & (feature.Action == 2)][['User_id']]\n",
    "    t['on_u9'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上用fixed购买的总次数\n",
    "    # on_u15\n",
    "    t = feature[(feature.Coupon_id == 'fixed') & (feature.Action == 1)][['User_id']]\n",
    "    t['on_u15'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on='User_id')\n",
    "    \n",
    "    # 用户线上领取次数\n",
    "    # on_u6\n",
    "    t = feature[(feature.Coupon_id != 'null') & (feature.Coupon_id != 'fixed')][['User_id']]\n",
    "    t['on_u6'] = 1\n",
    "    t = t.groupby('User_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上有发生购买的merchant个数\n",
    "    # on_u16\n",
    "    t = feature[feature.Action == 1][['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='on_u16')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # 用户线上有action的merchant个数\n",
    "    # on_u16\n",
    "    t = feature[['User_id', 'Merchant_id']]\n",
    "    t.drop_duplicates(inplace=True)\n",
    "    t = t.groupby('User_id').Merchant_id.agg('count').reset_index(name='on_u17')\n",
    "    dataset = pd.merge(dataset, t, how='left', on=['User_id'])\n",
    "    \n",
    "    # online_buy_use_coupon_fixed\n",
    "    # on_u17\n",
    "    dataset.on_u9.fillna(0, inplace=True)\n",
    "    dataset.on_u15.fillna(0, inplace=True)\n",
    "    dataset['on_u17'] = dataset.on_u9 + dataset.on_u15\n",
    "    \n",
    "    # online_buy_use_coupon_rate\n",
    "    # on_u18\n",
    "    dataset['on_u18'] = dataset.on_u9 / dataset.on_u4\n",
    "    \n",
    "    # online_buy_use_fixed_rate\n",
    "    # on_u19\n",
    "    dataset['on_u19'] = dataset.on_u15 / dataset.on_u4\n",
    "    \n",
    "    # online_buy_use_coupon_fixed_rate\n",
    "    # on_u20\n",
    "    dataset.on_u17.fillna(0, inplace=True)\n",
    "    dataset['on_u20'] = dataset.on_u17 / dataset.on_u4\n",
    "    \n",
    "    # online_coupon_transform_rate\n",
    "    # on_u21\n",
    "    dataset['on_u21'] = dataset.on_u9 / dataset.on_u6\n",
    "    \n",
    "    del t\n",
    "    print('...get online feature complete...')   \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ad135d310686d4e221fce56e06d2f1141f191055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "...get offline feature complete...\n",
      "...get online feature complete...\n",
      "(139785, 114) (262240, 114) (116204, 113) (116204, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = get_offline_feature(dataset1, off_feature1)\n",
    "dataset1 = get_online_feature(dataset1, on_feature1)\n",
    "dataset2 = get_offline_feature(dataset2, off_feature2)\n",
    "dataset2 = get_online_feature(dataset2, on_feature2)\n",
    "dataset3 = get_offline_feature(dataset3, off_feature3)\n",
    "dataset3 = get_online_feature(dataset3, on_feature3)\n",
    "\n",
    "del off_feature1, off_feature2, off_feature3\n",
    "del on_feature1, on_feature2, on_feature3\n",
    "\n",
    "# one-hot处理\n",
    "weekday_dummies = pd.get_dummies(dataset1.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset1 = pd.concat([dataset1, weekday_dummies], axis=1)\n",
    "weekday_dummies = pd.get_dummies(dataset2.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset2 = pd.concat([dataset2, weekday_dummies], axis=1)\n",
    "weekday_dummies = pd.get_dummies(dataset3.weekday)\n",
    "weekday_dummies.columns = ['weekday_' + str(i) for i in range(1, 8)]\n",
    "dataset3 = pd.concat([dataset3, weekday_dummies], axis=1)\n",
    "\n",
    "Submission = dataset3[['User_id', 'Coupon_id', 'Date_received']]\n",
    "\n",
    "# 删掉没用的列\n",
    "drop_columns = ['User_id', 'Merchant_id', 'Coupon_id', 'Discount_rate', 'Date_received', 'weekday']\n",
    "dataset1.drop(columns=drop_columns, inplace=True)\n",
    "dataset1.Distance.replace('null', -999, inplace=True)\n",
    "dataset1.Distance = dataset1.Distance.astype(int)\n",
    "dataset1.Distance.replace(-999, np.nan, inplace=True)\n",
    "dataset2.drop(columns=drop_columns, inplace=True)\n",
    "dataset2.Distance.replace('null', -999, inplace=True)\n",
    "dataset2.Distance = dataset2.Distance.astype(int)\n",
    "dataset2.Distance.replace(-999, np.nan, inplace=True)\n",
    "dataset3.drop(columns=drop_columns, inplace=True)\n",
    "dataset3.Distance.replace('null', -999, inplace=True)\n",
    "dataset3.Distance = dataset3.Distance.astype(int)\n",
    "dataset3.Distance.replace(-999, np.nan, inplace=True)\n",
    "\n",
    "print(dataset1.shape, dataset2.shape, dataset3.shape, Submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "222b915627cc1c463911afd826f3774cbf768a9e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset1.to_csv('../input/dataset1.csv', index=False)\n",
    "dataset2.to_csv('../input/dataset2.csv', index=False)\n",
    "dataset3.to_csv('../input/dataset3.csv', index=False)\n",
    "Submission.to_csv('../input/Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
